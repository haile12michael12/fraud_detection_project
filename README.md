# ğŸ›¡ï¸ Fraud Detection and Credit Risk Modeling Project

## ğŸ“Œ Project Overview
This project focuses on identifying fraudulent transactions and assessing credit risk using machine learning and deep learning techniques. It involves:
- Preprocessing and merging multiple datasets.
- Building interpretable classification models.
- Applying explainability techniques (SHAP & LIME).
- Deploying predictive models via an API.

The ultimate goal is to create robust, explainable systems that detect fraud and analyze transaction behavior in both traditional and credit card data.

---

## ğŸ“‚ Datasets Used

### 1. `Fraud_Data.csv`
Contains detailed transaction info:
- `user_id`, `signup_time`, `purchase_time`, `purchase_value`, `device_id`, `source`, `browser`, `sex`, `age`, `ip_address`, and `class` (fraud indicator).

### 2. `Credit_Card_Transactions.csv`
An anonymized dataset:
- Features: `v1` to `v8`, `Time`, `amount`, and `Class` (fraud indicator).

### 3. `IpAddress_to_Country.csv`
Maps IP addresses to countries:
- `lower_bound_ip_address`, `upper_bound_ip_address`, `country`.

---

## ğŸ§¹ Task 1: Data Analysis and Preprocessing

### âœ… Data Cleaning
- Removed duplicates and corrected data types.
- Handled missing values via imputation or removal.

### ğŸ“Š Exploratory Data Analysis (EDA)
- Univariate and bivariate analysis to detect trends.
- Visualized class imbalance, temporal fraud patterns, and feature correlations.

### ğŸŒ Geolocation Mapping
- Converted IP addresses to integers.
- Merged `Fraud_Data.csv` with `IpAddress_to_Country.csv` to analyze country-level fraud patterns.

### ğŸ—ï¸ Feature Engineering
- **Time-Based**:
  - `hour_of_day`, `day_of_week`, `time_since_signup`
- **Behavioral**:
  - Transaction frequency and velocity

### ğŸ” Data Transformation
- Addressed **class imbalance** with SMOTE and Random Undersampling.
- Scaled numerical features using `StandardScaler`.
- Applied One-Hot Encoding to categorical features.

---

## ğŸ¤– Task 2: Model Building and Training

### âš™ï¸ Data Preparation
- Separated features and labels (`class` / `Class`).
- Applied train-test split strategy with stratification.

### ğŸ“Œ Models Built
1. **Logistic Regression** (Baseline)
2. **Ensemble Model** (XGBoost / Random Forest)

### ğŸ“ˆ Evaluation Metrics
- **F1 Score**
- **Confusion Matrix**
- **AUC-PR (Precision-Recall)**
  
**Best Model Justification**: Based on F1 Score and PR AUC on imbalanced test sets.

---

## ğŸ§  Task 3: Model Explainability

### ğŸ” SHAP (Shapley Additive exPlanations)
- Used `TreeExplainer` and `KernelExplainer` on traditional and deep models.
- Summary plots reveal global feature importance.
- Force plots used for local, instance-level interpretation.

### ğŸŒˆ LIME (Local Interpretable Model-Agnostic Explanations)
- Explained predictions on individual transactions.
- Demonstrated how specific feature values influence fraud classification.

---

## ğŸ”Œ Model Deployment

### Flask API + Docker

#### Model API Supports:
- âœ… **Fraud Detection Model** (Decision Tree)
- âœ… **Credit Card Detection Model** (RNN)

### Project Structure:

## Project Structure
```
fraud-detection-project/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ unittests.yml
â”‚
â”œâ”€â”€ .vscode/
â”‚   â””â”€â”€ settings.json
â”‚
â”œâ”€â”€ ceaned_data/
â”‚   â”œâ”€â”€ preprocessed_Fraud_Data.csv
â”‚   â”œâ”€â”€ merged_data.csv
â”‚   â”œâ”€â”€ preprocessed_Credit_Card_Transactions.csv
â”‚   â””â”€â”€ preprocessed_IpAddress_to_Country.csv
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Fraud_Data.csv
â”‚   â”œâ”€â”€ Credit_Card_Transactions.csv
â”‚   â””â”€â”€ IpAddress_to_Country.csv
â”‚
â”œâ”€â”€ DL_saved_models/
â”‚
â”œâ”€â”€ saved_models/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_preprocessing.ipynb
â”‚   â”œâ”€â”€ ML_model_creaditcard_data.ipynb
â”‚   â”œâ”€â”€ ML_model_fraud_data.ipynb
â”‚   â”œâ”€â”€ model_Building_Training.ipynb   // DL models for both credit and fraud data
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ __init__.py
|
â”œâ”€â”€ src/
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ test/
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- Libraries listed in `requirements.txt`

### Installation
```
git clone https://github.com/YourUsername/Fraud_Detection_Project.git
cd Fraud_Detection_Project

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

Running Jupyter Notebooks
jupyter notebook

Launching Flask API

cd model_api
python serve_model.py
```
---

##  ğŸ“Š Results and Insights
- Identified key drivers of fraud:

- Signup-purchase time gap

- Device/browser usage

- Transaction timing (odd hours)

- SHAP revealed model bias toward certain time and value patterns.

- Ensemble models outperformed logistic regression on both datasets.

## ğŸ“œ License
- This project is open-source and available under the MIT License

- Let me know if youâ€™d like the `README.md` exported as a file or customized with your GitHub repo link, author profile, or badges!
